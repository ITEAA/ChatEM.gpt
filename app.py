from flask import Flask, request, jsonify
import time
import requests
import os
import re
import xml.etree.ElementTree as ET
from functools import lru_cache
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI()

app = Flask(__name__)
app.secret_key = os.getenv("FLASK_SECRET_KEY")
assistant_id = os.getenv("ASSISTANT_ID")
job_api_key = os.getenv("JOB_API_KEY")


def extract_keywords_from_resume(text):
    prompt = f"ë‹¤ìŒ ìê¸°ì†Œê°œì„œì—ì„œ í•µì‹¬ ê¸°ìˆ , ì§ë¬´, ê²½í—˜ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ ì¶”ì¶œí•´ì¤˜:\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return [kw.strip() for kw in response.choices[0].message.content.split(",")]
    except Exception as e:
        print("âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨:", e)
        return ["ê°œë°œ", "íŒ€ì›Œí¬", "ë¬¸ì œí•´ê²°"]  # fallback í‚¤ì›Œë“œ


def parse_user_preferences(text):
    prefs = re.findall(r"\d+\.\s*([^\n]*)", text)
    return [p.strip() for p in prefs]


@lru_cache(maxsize=100)
def build_company_list_from_job_api(keyword, rows=10):
    url = "https://118.67.151.173/data/api/jopblancApi.do"
    params = {
        "authKey": job_api_key,
        "callTp": "L",
        "listCount": rows,
        "query": keyword
    }
    try:
        response = requests.get(url, params=params, verify=False, timeout=10)
        print("ğŸ“¡ API ìš”ì²­ URL:", response.url)
        print("ğŸ” ì‘ë‹µ ìƒíƒœ ì½”ë“œ:", response.status_code)

        companies = []
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            for item in root.findall(".//jobList"):
                name = item.findtext("entrprsNm", "ê¸°ì—…ëª… ì—†ìŒ")
                area = item.findtext("areaStr", "")
                style = item.findtext("emplymStleSeStr", "")
                duty = item.findtext("dtyStr", "")
                title = item.findtext("pblancSj", "")
                tags = [t for t in [area, style, duty] if t]
                tags += title.split()  # ì œëª© ë‹¨ì–´ë„ íƒœê·¸ì— í¬í•¨
                companies.append({"name": name, "tags": tags})
        return companies

    except Exception as e:
        print("âŒ API ìš”ì²­ ì˜¤ë¥˜:", str(e))
        return []


def get_job_postings(keyword, rows=3):
    url = "https://118.67.151.173/data/api/jopblancApi.do"
    params = {
        "authKey": job_api_key,
        "callTp": "L",
        "listCount": rows,
        "query": keyword
    }
    try:
        response = requests.get(url, params=params, verify=False, timeout=10)
        postings = []
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            for item in root.findall(".//jobList"):
                postings.append({
                    "entrprsNm": item.findtext("entrprsNm", ""),
                    "title": item.findtext("pblancSj", ""),
                    "regionNm": item.findtext("areaStr", ""),
                    "emplmntTypeNm": item.findtext("emplymStleSeStr", ""),
                    "linkUrl": "https://www.job.kosmes.or.kr/job/jbd/jobDetail.do?seq=" + item.findtext("jopblancIdx", "")
                })
        return postings
    except Exception as e:
        print("âŒ ì±„ìš©ê³µê³  íŒŒì‹± ì˜¤ë¥˜:", str(e))
        return []


# âœ… ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
def compute_similarity(text1, text2):
    try:
        emb1 = client.embeddings.create(input=text1, model="text-embedding-ada-002").data[0].embedding
        emb2 = client.embeddings.create(input=text2, model="text-embedding-ada-002").data[0].embedding
        return cosine_similarity(emb1, emb2)
    except Exception as e:
        print("âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨:", str(e))
        return 0.0


def cosine_similarity(a, b):
    dot = sum(x * y for x, y in zip(a, b))
    norm_a = sum(x * x for x in a) ** 0.5
    norm_b = sum(y * y for y in b) ** 0.5
    return dot / (norm_a * norm_b)


def match_company_to_user(companies, user_keywords, user_prefs):
    user_text = " ".join(user_keywords + user_prefs)
    best = None
    best_score = -1

    for company in companies:
        company_text = " ".join(company["tags"])
        score = compute_similarity(user_text, company_text)
        if score > best_score:
            best = company
            best_score = score
    return best or (companies[0] if companies else None)


def build_explanation_prompt(keywords, preferences, company, job_summary=""):
    base = f"ë‹¤ìŒ ì‚¬ìš©ì ì •ë³´ì™€ ì¶”ì²œ ê¸°ì—…ì„ ê¸°ë°˜ìœ¼ë¡œ, ì™œ ì´ ê¸°ì—…ì´ ì í•©í•œì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n"
    base += f"[ì‚¬ìš©ì ì •ë³´]\n- í‚¤ì›Œë“œ: {', '.join(keywords)}\n- ì„ í˜¸: {', '.join(preferences)}\n\n"
    base += f"[ì¶”ì²œ ê¸°ì—…]\n- ê¸°ì—…ëª…: {company['name']}\n- íƒœê·¸: {', '.join(company['tags'])}"
    if job_summary:
        base += f"\n\n[ì±„ìš©ê³µê³ ]\n{job_summary}"
    return base

@app.route("/")
def home():
    return jsonify({"message": "ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤ ğŸš€"})
    
# âœ… Fly.io í˜¸í™˜ í¬íŠ¸ ì„¤ì •
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
