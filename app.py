from flask import Flask, request, jsonify, render_template
import os
import re
import requests
import xml.etree.ElementTree as ET
from functools import lru_cache
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI()

app = Flask(__name__)
app.secret_key = os.getenv("FLASK_SECRET_KEY")
assistant_id = os.getenv("ASSISTANT_ID")
job_api_key = os.getenv("JOB_API_KEY")
proxy_url = os.getenv("PROXY_URL", "http://127.0.0.1:5001/proxy")

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    try:
        user_input = request.form.get("message", "")

        if len(user_input.strip()) < 5:
            return jsonify({"reply": "ê°„ë‹¨í•œ ì¸ì‚¬ë§ë³´ë‹¤ëŠ” ê´€ì‹¬ ë¶„ì•¼ë‚˜ ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” ğŸ˜Š"})

        resume = extract_resume_text(user_input)
        keywords = extract_keywords(resume)
        user_prefs = extract_user_preferences(user_input)

        companies = build_company_list_from_proxy_api("ê°œë°œ")
        match = match_company_to_user(companies, keywords, user_prefs)

        if not match:
            return jsonify({"reply": "âŒ ê¸°ì—… ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."})

        prompt = build_explanation_prompt(keywords, user_prefs, match)
        reply = get_gpt_reply(prompt)

        return jsonify({"reply": reply})
    except Exception as e:
        return jsonify({"reply": f"âŒ ì„œë²„ ì˜¤ë¥˜: {str(e)}"}), 500

def extract_resume_text(text):
    return text

def extract_user_preferences(text):
    return parse_user_preferences(text)

def extract_keywords(text):
    prompt = f"ë‹¤ìŒ ìê¸°ì†Œê°œì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì‰¼í‘œë¡œ ì¶”ì¶œí•´ì¤˜:\n{text}"
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return [kw.strip() for kw in response.choices[0].message.content.split(",") if kw.strip()]
    except Exception as e:
        print("âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨:", e)
        return ["AI", "í”„ë¡œê·¸ë˜ë°", "íŒ€ì›Œí¬"]

def parse_user_preferences(text):
    prefs = re.findall(r"\d+\.\s*([^\n]*)", text)
    return [p.strip() for p in prefs]

@lru_cache(maxsize=100)
def build_company_list_from_proxy_api(keyword, rows=10):
    try:
        params = {
            "authKey": job_api_key,
            "callTp": "L",
            "listCount": rows,
            "query": keyword,
        }
        response = requests.get(proxy_url, params=params, timeout=10)
        companies = []
        if response.status_code == 200:
            root = ET.fromstring(response.content)
            for item in root.findall(".//jobList"):
                name = item.findtext("entrprsNm", "ê¸°ì—…ëª… ì—†ìŒ")
                tags = [item.findtext(k, '') for k in ["areaStr", "emplymStleSeStr", "dtyStr"] if item.findtext(k)]
                title = item.findtext("pblancSj", "")
                tags += title.split()
                companies.append({"name": name, "tags": tags})
            return companies
    except Exception as e:
        print("âŒ Proxy API ì˜¤ë¥˜:", str(e))
    return []

def compute_similarity(text1, text2):
    try:
        emb1 = client.embeddings.create(input=text1, model="text-embedding-ada-002").data[0].embedding
        emb2 = client.embeddings.create(input=text2, model="text-embedding-ada-002").data[0].embedding
        return cosine_similarity(emb1, emb2)
    except Exception as e:
        print("âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨:", str(e))
        return 0.0

def cosine_similarity(a, b):
    dot = sum(x * y for x, y in zip(a, b))
    norm_a = sum(x * x for x in a) ** 0.5
    norm_b = sum(y * y for y in b) ** 0.5
    return dot / (norm_a * norm_b)

def match_company_to_user(companies, user_keywords, user_prefs):
    user_text = " ".join(user_keywords + user_prefs)
    best, best_score = None, -1
    for company in companies:
        company_text = " ".join(company["tags"])
        score = compute_similarity(user_text, company_text)
        if score > best_score:
            best, best_score = company, score
    return best

def build_explanation_prompt(keywords, preferences, company):
    base = f"ì‚¬ìš©ì ì •ë³´ì™€ ì¶”ì²œ ê¸°ì—… ê¸°ë°˜ ì„¤ëª…:\n"
    base += f"[í‚¤ì›Œë“œ] {', '.join(keywords)}\n[ì„ í˜¸] {', '.join(preferences)}\n"
    base += f"[ì¶”ì²œ ê¸°ì—…] {company['name']}\n[íƒœê·¸] {', '.join(company['tags'])}"
    return base

def get_gpt_reply(prompt):
    try:
        response = client.chat.completions.create(
            model="gpt-4-1106-preview",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        return response.choices[0].message.content
    except Exception as e:
        print("âŒ GPT ì‘ë‹µ ì‹¤íŒ¨:", e)
        return "GPT ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
