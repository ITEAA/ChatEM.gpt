import os
import json
import fitz  # PyMuPDF
import openai
import random
import xml.etree.ElementTree as ET
import requests
import pandas as pd

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
CORS(app)

openai.api_key = os.getenv("OPENAI_API_KEY") or "your-api-key"
GG_API_KEY = "8af0f404ca144249be0cfab9728b619b"
GG_API_URL = "https://openapi.gg.go.kr/EmplmntInfoStus"

user_states = {}

# Load company data
with open("ChatEM_top20_companies.json", "r", encoding="utf-8") as f:
    company_data = json.load(f)

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = "\n".join(page.get_text() for page in doc)
    return text.strip()

def extract_keywords(text):
    prompt = f"""
    ë‹¤ìŒ ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.
    - 5~10ê°œ ì •ë„ ë½‘ì•„ì¤˜.
    - í‚¤ì›Œë“œëŠ” ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ì¤˜.

    ë‚´ìš©:
    {text}
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        result = response.choices[0].message.content
        return [kw.strip() for kw in result.split(",") if kw.strip()]
    except Exception as e:
        print(f"âŒ GPT í˜¸ì¶œ ì—ëŸ¬: {e}")
        return []

def fetch_gg_employment_info(index=1, size=100):
    print("ğŸ“¡ [API í˜¸ì¶œë¨] ê²½ê¸°ë„ ê³ ìš©ì •ë³´ API ìš”ì²­ ì¤‘...")
    params = {"KEY": GG_API_KEY, "Type": "xml", "pIndex": index, "pSize": size}
    try:
        response = requests.get(GG_API_URL, params=params)
        root = ET.fromstring(response.content)
        rows = root.findall(".//row")

        data = []
        for row in rows:
            row_data = [row.find(col).text if row.find(col) is not None else "" for col in [
                "REGIST_DE", "SIGUN_NM", "COMPNY_NM", "EMPLMNT_TITLE", "WAGE_FORM", "SALARY_INFO",
                "WORK_REGION_LOC", "WORK_FORM", "MIN_ACDMCR", "CAREER_INFO", "CLOS_DE_INFO", "EMPLMNT_INFO_URL"
            ]]
            data.append(row_data)

        columns = ["ë“±ë¡ì¼ì", "ì‹œêµ°ëª…", "íšŒì‚¬ëª…", "ì±„ìš©ê³µê³ ëª…", "ì„ê¸ˆí˜•íƒœ", "ê¸‰ì—¬", "ê·¼ë¬´ì§€ì—­", "ê·¼ë¬´í˜•íƒœ",
                   "ìµœì†Œí•™ë ¥", "ê²½ë ¥", "ë§ˆê°ì¼ì", "ì±„ìš©ì •ë³´URL"]
        df = pd.DataFrame(data, columns=columns)
        return df.to_dict(orient="records")
    except Exception as e:
        print(f"âŒ ê³ ìš©ì •ë³´ API ì˜¤ë¥˜: {e}")
        return []

def filter_companies(keywords, interest=None, region=None, salary=None):
    filtered = []
    for company in company_data:
        content = f"{company.get('name', '')} {company.get('summary', '')}".lower()
        if any(k.lower() in content for k in keywords):
            filtered.append(company)
    return filtered

def tfidf_similarity(user_text, companies):
    def get_summary(company):
        return company.get("summary") or f"{company.get('name')}ì—ì„œ {company.get('summary')}"

    documents = [user_text] + [get_summary(c) for c in companies]
    tfidf = TfidfVectorizer().fit_transform(documents)
    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
    scored = sorted(zip(cosine_sim, companies), key=lambda x: x[0], reverse=True)
    return [(c, round(s, 2)) for s, c in scored]

def generate_reason(user_text, companies_with_scores):
    prompt = f"""
ë‹¹ì‹ ì€ ì±„ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê° ê¸°ì—…ì˜ ì§ë¬´ì™€ ì™œ ì í•©í•œì§€ ë¶„ì„ê°€ ì…ì¥ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
ê° ê¸°ì—…ë§ˆë‹¤ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ì¶œë ¥í•´ ì£¼ì„¸ìš”:

ê¸°ì—…ëª…: OOO
ì—…ë¬´: OOO
ìœ ì‚¬ë„ ì ìˆ˜: 0.XX
ì„¤ëª…: OOO

[ìê¸°ì†Œê°œì„œ ë‚´ìš©]
{user_text}

[ê¸°ì—… ëª©ë¡ ë° ìœ ì‚¬ë„ ì ìˆ˜]
{json.dumps([{"ê¸°ì—…ëª…": c.get('name'), "ì—…ë¬´": c.get('summary'), "ì ìˆ˜": score} for c, score in companies_with_scores], ensure_ascii=False)}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content + "\n\nğŸ“Œ ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë ¤í•˜ê³  ì‹¶ì€ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶”ê°€ë¡œ ë°˜ì˜í•´ ë“œë¦´ê²Œìš”!"
    except Exception as e:
        print(f"âŒ GPT ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {e}")
        return "ì¶”ì²œ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_id = request.remote_addr
    message = request.form.get("message", "").strip()
    file = request.files.get("file")
    state = user_states.get(user_id, {})

    try:
        if file:
            state["user_text"] = extract_text_from_pdf(file)

        if message and "," in message and "ë§Œì›" in message:
            parts = [p.strip() for p in message.replace("ë§Œì›", "").split(",")]
            state["interest"] = parts[0] if len(parts) > 0 else ""
            state["region"] = parts[1] if len(parts) > 1 else ""
            state["salary"] = parts[2] if len(parts) > 2 else ""

        if message and "user_text" not in state:
            state["user_text"] = message

        if "user_text" in state and "interest" in state:
            keywords = extract_keywords(state["user_text"])
            filtered = filter_companies(keywords, state.get("interest"), state.get("region"), state.get("salary"))
            if not filtered:
                filtered = company_data
            matched = tfidf_similarity(state["user_text"], filtered)
            selected = matched[:3]
            explanation = generate_reason(state["user_text"], selected)
            return jsonify({"reply": explanation})

        missing = []
        if "user_text" not in state:
            missing.append("ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œ")
        if "interest" not in state:
            missing.append("ê´€ì‹¬ ë¶„ì•¼, í¬ë§ ê·¼ë¬´ì§€, í¬ë§ ì—°ë´‰")
        if missing:
            return jsonify({"reply": f"ë¨¼ì € {', '.join(missing)}ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."})

        return jsonify({"reply": "ì…ë ¥ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."})

    except Exception as e:
        print(f"âŒ ì„œë²„ ì—ëŸ¬: {e}")
        return jsonify({"reply": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=8080)
