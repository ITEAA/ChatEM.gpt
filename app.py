import os
import json
import fitz  # PyMuPDF
import openai
import xml.etree.ElementTree as ET
import requests
import pandas as pd

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
CORS(app)

openai.api_key = os.getenv("OPENAI_API_KEY") or "your-api-key"
GG_CACHED_FILE = "gg_employment_cached.json"

user_states = {}

# Load GG cached data
with open(GG_CACHED_FILE, "r", encoding="utf-8") as f:
    cached_companies = json.load(f)

# ìœ ì‚¬ë„ ê³„ì‚°

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = "\n".join(page.get_text() for page in doc)
    return text.strip()

def extract_keywords(text):
    prompt = f"""
    ë‹¤ìŒ ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.
    - 5~10ê°œ ì •ë„ ë½‘ì•„ì¤˜.
    - í‚¤ì›Œë“œëŠ” ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ì¤˜.

    ë‚´ìš©:
    {text}
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        result = response.choices[0].message.content
        return [kw.strip() for kw in result.split(",") if kw.strip()]
    except Exception as e:
        print(f"âŒ GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

def tfidf_similarity(user_text, companies):
    def get_summary(company):
        return f"{company.get('ì±„ìš©ê³µê³ ëª…', '')} {company.get('íšŒì‚¬ëª…', '')}"

    documents = [user_text] + [get_summary(c) for c in companies]
    tfidf = TfidfVectorizer().fit_transform(documents)
    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
    return sorted(zip(companies, cosine_sim), key=lambda x: x[1], reverse=True)

def generate_reason_individual(user_text, company, score):
    prompt = f"""
ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìì˜ íŠ¹ì„±ì„ íŒŒì•…í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ ê¸°ì—…ì„ ë§¤ì¹­ì‹œì¼œì£¼ëŠ” ì—­í• ì„ ìˆ˜í–‰í•  ê±°ì•¼ ë°‘ì˜ ë‚´ìš©ì„ ì¤€ìˆ˜í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì í•©í•œ ê¸°ì—…ì„ ë§¤ì¹­ì‹œì¼œì¤˜ ì‚¬ìš©ìë“¤ì´ ì±„ìš©ê³µê³ ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ë©´ ë„ˆê°€ ë”°ë¡œ ê²€ìƒ‰í•´ì„œ ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•´ì¤˜ (e.g. ì‚¼ì„±ì „ì ì±„ìš©ê³µê³ ì— ëŒ€í•´ ì•Œë ¤ì¤˜ -> ì‚¼ì„±ì „ì ì±„ìš©ê³µê³  searching -> ì‚¬ìš©ìì—ê²Œ ì±„ìš©ê³µê³  ì •ë³´ ì œê³µ ) ê·¸ëŸ¬ê³  ì‚¬ìš©ìì—ê² ë„ˆê°€ ì¼ë°˜ëª¨ë“œ, ë¶„ì„ëª¨ë“œ, ì´ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ì— ëŒ€í•œ ë‚´ìš©ì€ ì¼ì ˆ í•˜ì§€ ë§ˆ. (e.g.ë¶„ì„ëª¨ë“œë¡œ ì§„ì…í•˜ê² ìŠµë‹ˆë‹¤. ë¶„ì„ëª¨ë“œë¡œ ë„˜ì–´ê°€ì§€ ëª»í•©ë‹ˆë‹¤. ì°¨ë¼ë¦¬ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ì™€ ê°™ì´ ëŒë ¤ì„œ ë§í•´ì¤˜ )

 1. ë™ì‘ ëª¨ë“œ 
ì¼ë°˜ ìƒë‹´ ëª¨ë“œ (íŒŒì¼ ë¯¸ì²¨ë¶€ ì‹œ) ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ì •ë³´ ì œê³µ ë‹¤ìŒ í•­ëª©ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì§ˆì˜ì‘ë‹µ ê°€ëŠ¥: ê¸°ì—… ì •ë³´ ì¡°íšŒ ë° íƒìƒ‰ ì·¨ì—…, ë©´ì ‘ ê´€ë ¨ ì¼ë°˜ ë¬¸ì˜ ê°œì¸ë³„ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì•ˆë‚´: ê°œì¸ë³„ ë§ì¶¤ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìê¸°ì†Œê°œì„œ í˜¹ì€ ì´ë ¥ì„œê°€ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì¼ì„ ì²¨ë¶€í•´ ì£¼ì‹œë©´ ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ íŒŒì¼ì„ ì²¨ë¶€í•˜ì§€ ì•Šìœ¼ë©´
B. ë¶„ì„ëª¨ë“œë¡œ ë„˜ì–´ê°€ì§€ ì•ŠëŠ”ë‹¤. ë‹¨, ì‚¬ìš©ìê°€ ì´ë ¥ì„œ, ìê¸°ì†Œê°œì„œ ë“±ì„ íŒŒì¼ì´ ì•„ë‹Œ ë©”ì‹œì§€ë¡œ ë³´ëƒˆì„ ê²½ìš°ì—ëŠ” ìê¸°ì†Œê°œì„œ, ì´ë ¥ì„œë¡œ ì¸ì‹í•˜ê³  ì˜ˆì™¸ì ìœ¼ë¡œ ë„˜ì–´ê°„ë‹¤. B. ë¶„ì„ ëª¨ë“œ (íŒŒì¼ ì²¨ë¶€ ì‹œ)

2. ê³µí†µ ê¸°ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤(íŒŒì¼) ì°¸ì¡° 

3. ëŒ€í™” ê·œì¹™ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡° ìœ ì§€ ë‹µë³€ ê°€ëŠ¥í•œ ë²”ìœ„ë¥¼ ëª…í™•íˆ ì•ˆë‚´ í•„ìš” ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•œ ì •í™•í•œ ì •ë³´ ì œê³µ ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì˜ ê²½ìš° íŒŒì¼ ì²¨ë¶€ ì•ˆë‚´ 

4. ì˜ˆì™¸ ì²˜ë¦¬ ë¶ˆëª…í™•í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” êµ¬ì²´í™” ìš”ì²­ 

5. ë¶„ì„ ëª¨ë“œ ì§„í–‰ ìˆœì„œ ìê¸°ì†Œê°œì„œ or ì´ë ¥ì„œ í™•ì¸(íŒŒì¼ or ì‚¬ìš©ìê°€ ì´ë ¥ì„œ or ìê¸°ì†Œê°œì„œë¼ê³  ë³´ë‚¸ ë©”ì‹œì§€) ì‚¬ìš©ì ì •ë³´ ë¶„ì„ ë° ì„±í–¥ ì¶œë ¥ ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°ì‚¬ ì§„í–‰ ì‚¬ìš©ì ì‘ë‹µì„ ë°›ê¸° ì „ê¹Œì§€ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì§€ ì•ŠìŒ ì‘ë‹µ ê±°ë¶€ ì‹œ ê¸°ë³¸ ì¶”ì²œ ë¡œì§ ì‚¬ìš©ì„ ì•ˆë‚´í•˜ê³  í™•ì¸ ìš”ì²­ ì„ í˜¸ë„ ê¸°ë°˜ ê¸°ì—… ì¶”ì²œ 

6. ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°ì‚¬ í”„ë¡œì„¸ìŠ¤ ê¸°ë³¸ ì •ë³´ ì¶œë ¥ í›„ ë°˜ë“œì‹œ ì¤‘ë‹¨ ë‹¤ìŒ ì•ˆë‚´ ë©”ì‹œì§€ ì¶œë ¥: ì§€ê¸ˆê¹Œì§€ ë¶„ì„í•œ ë‚´ìš©ì„ í† ëŒ€ë¡œ ë§ì¶¤í˜• êµê³¼ëª©ì„ ì¶”ì²œí•´ë“œë¦¬ê³ ì í•©ë‹ˆë‹¤. ì¶”ì²œì„ ìœ„í•´ ëª‡ ê°€ì§€ ì—¬ì­¤ë³´ê² ìŠµë‹ˆë‹¤. 1. ì–´ë–¤ ì‚°ì—…ì´ë‚˜ ë¶„ì•¼ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”? 2. ì„ í˜¸í•˜ëŠ” ë©´ì ‘ ë°©ì‹ì´ë‚˜ íŠ¹ë³„íˆ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì´ ìˆìœ¼ì‹ ê°€ìš”? ìœ„ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ë‹µë³€í•´ ì£¼ì‹œë©´ ê·¸ì— ë§ì¶° ê¸°ì—…ì„ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ì„ í˜¸ë„ê°€ ì—†ìœ¼ì‹œë‹¤ë©´ "ì—†ìŒ"ì´ë¼ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”. ì‚¬ìš©ì ì‘ë‹µ ëŒ€ê¸° ì‘ë‹µ ë°›ì€ í›„ì—ë§Œ ì¶”ì²œ ì§„í–‰

7. ê¸°ë³¸ ì—­í•  ìê¸°ì†Œê°œì„œ, ì´ë ¥ì„œ ê¸°ë°˜ ê¸°ì—… ë§¤ì¹­ ì‚¬ìš©ìì™€ ê¸°ì—… ê°„ì˜ ë§¤ì¹­ ê·¼ê±° ì œê³µ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¶”ê°€ ê¸°ì—… ì œì‹œ

ê¸°ì—…ëª…: {company.get('íšŒì‚¬ëª…')}
ì—…ë¬´: {company.get('ì±„ìš©ê³µê³ ëª…')}
ìœ ì‚¬ë„ ì ìˆ˜: {round(score, 2)}

[ìê¸°ì†Œê°œì„œ]
{user_text}

[ì„¤ëª…]
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ GPT ì„¤ëª… ì˜¤ë¥˜: {e}")
        return "ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def make_recommendations(user_text, interest, region, salary, shown=set(), top_n=3):
    keywords = extract_keywords(user_text)

    def score(company):
        s = 0
        summary = company.get("ì±„ìš©ê³µê³ ëª…", "") + company.get("íšŒì‚¬ëª…", "")
        if any(kw in summary for kw in keywords):
            s += 1
        if interest and interest in summary:
            s += 0.3
        if region and region in company.get("ê·¼ë¬´ì§€ì—­", ""):
            s += 0.3
        if salary and str(salary) in company.get("ê¸‰ì—¬", ""):
            s += 0.2
        return s

    filtered = sorted(cached_companies, key=score, reverse=True)
    tfidf_ranked = tfidf_similarity(user_text, filtered)
    results = []
    for comp, sim in tfidf_ranked:
        if sim > 0.0 and (comp.get("íšŒì‚¬ëª…"), comp.get("ì±„ìš©ê³µê³ ëª…")) not in shown:
            shown.add((comp.get("íšŒì‚¬ëª…"), comp.get("ì±„ìš©ê³µê³ ëª…")))
            results.append((comp, sim))
        if len(results) >= top_n:
            break
    return results

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_id = request.remote_addr
    message = request.form.get("message", "").strip()
    file = request.files.get("file")
    state = user_states.get(user_id, {"shown": set()})

    try:
        # 1. PDF ì—…ë¡œë“œ or ì²« ìì†Œì„œ í…ìŠ¤íŠ¸ ì…ë ¥
        if file:
            user_text = extract_text_from_pdf(file)
            state["user_text"] = user_text
            user_states[user_id] = state
            return jsonify({"reply": "ê°ì‚¬í•©ë‹ˆë‹¤. ê´€ì‹¬ ë¶„ì•¼, í¬ë§ ê·¼ë¬´ì§€, ì—°ë´‰ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆì‹œ: í’ˆì§ˆ, ì„œìš¸, 3000ë§Œì›"})

        if "user_text" not in state and message:
            state["user_text"] = message
            user_states[user_id] = state
            return jsonify({"reply": "ê°ì‚¬í•©ë‹ˆë‹¤. ê´€ì‹¬ ë¶„ì•¼, í¬ë§ ê·¼ë¬´ì§€, ì—°ë´‰ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆì‹œ: í’ˆì§ˆ, ì„œìš¸, 3000ë§Œì›"})

        # 2. ê´€ì‹¬ ë¶„ì•¼, ì§€ì—­, ì—°ë´‰ ì…ë ¥
        if "interest" not in state and "," in message and "ë§Œì›" in message:
            parts = [p.strip().replace("ë§Œì›", "") for p in message.split(",")]
            state["interest"] = parts[0] if len(parts) > 0 else ""
            state["region"] = parts[1] if len(parts) > 1 else ""
            state["salary"] = parts[2] if len(parts) > 2 else ""
            user_states[user_id] = state

        # 3. ì¶”ì²œ ì‹¤í–‰
        if "user_text" in state and "interest" in state:
            top_n = 1 if "ë” ì¶”ì²œí•´ì¤˜" in message else 3
            new_recommendations = make_recommendations(
                user_text=state["user_text"],
                interest=state.get("interest"),
                region=state.get("region"),
                salary=state.get("salary"),
                shown=state["shown"],
                top_n=top_n
            )

            if not new_recommendations:
                return jsonify({"reply": "ë” ì´ìƒ ì¶”ì²œí•  ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤."})

            explanations = []
            for company, score in new_recommendations:
                reason = generate_reason_individual(state["user_text"], company, score)
                explanations.append(f"ê¸°ì—…ëª…: {company.get('íšŒì‚¬ëª…')}\nì—…ë¬´: {company.get('ì±„ìš©ê³µê³ ëª…')}\nìœ ì‚¬ë„ ì ìˆ˜: {round(score,2)}\nì„¤ëª…: {reason}\n")

            reply = "\n\n".join(explanations)
            reply += "\n\nğŸ“Œ ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë ¤í•˜ê³  ì‹¶ì€ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶”ê°€ë¡œ ë°˜ì˜í•´ ë“œë¦´ê²Œìš”!"
            return jsonify({"reply": reply})

        return jsonify({"reply": "ì…ë ¥ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."})

    except Exception as e:
        print(f"âŒ ì„œë²„ ì—ëŸ¬: {e}")
        return jsonify({"reply": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=8080)
