# âœ… app.py
import os
import json
import fitz  # PyMuPDF
import openai
import random
import xml.etree.ElementTree as ET
import requests
import pandas as pd

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
CORS(app)

openai.api_key = os.getenv("OPENAI_API_KEY") or "your-api-key"
GG_API_KEY = "8af0f404ca144249be0cfab9728b619b"
GG_API_URL = "https://openapi.gg.go.kr/EmplmntInfoStus"

user_states = {}

with open("ChatEM_top20_companies.json", "r", encoding="utf-8") as f:
    company_data = json.load(f)

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = "\n".join(page.get_text() for page in doc)
    return text.strip()

def extract_keywords(text):
    prompt = f"""
    ë‹¤ìŒ ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.
    - 5~10ê°œ ì •ë„ ë½‘ì•„ì¤˜.
    - í‚¤ì›Œë“œëŠ” ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ì¤˜.

    ë‚´ìš©:
    {text}
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        result = response.choices[0].message.content
        return [kw.strip() for kw in result.split(",") if kw.strip()]
    except Exception as e:
        print(f"âŒ GPT í˜¸ì¶œ ì—ëŸ¬: {e}")
        return []

def fetch_gg_employment_info(index=1, size=100):
    params = {"KEY": GG_API_KEY, "Type": "xml", "pIndex": index, "pSize": size}
    try:
        response = requests.get(GG_API_URL, params=params)
        root = ET.fromstring(response.content)
        rows = root.findall(".//row")

        data = []
        for row in rows:
            row_data = [row.find(col).text if row.find(col) is not None else "" for col in [
                "REGIST_DE", "SIGUN_NM", "COMPNY_NM", "EMPLMNT_TITLE", "WAGE_FORM", "SALARY_INFO",
                "WORK_REGION_LOC", "WORK_FORM", "MIN_ACDMCR", "CAREER_INFO", "CLOS_DE_INFO", "EMPLMNT_INFO_URL"
            ]]
            data.append(row_data)

        columns = ["ë“±ë¡ì¼ì", "ì‹œêµ°ëª…", "íšŒì‚¬ëª…", "ì±„ìš©ê³µê³ ëª…", "ì„ê¸ˆí˜•íƒœ", "ê¸‰ì—¬", "ê·¼ë¬´ì§€ì—­", "ê·¼ë¬´í˜•íƒœ",
                   "ìµœì†Œí•™ë ¥", "ê²½ë ¥", "ë§ˆê°ì¼ì", "ì±„ìš©ì •ë³´URL"]
        df = pd.DataFrame(data, columns=columns)
        return df.to_dict(orient="records")
    except Exception as e:
        print(f"âŒ ê³ ìš©ì •ë³´ API ì˜¤ë¥˜: {e}")
        return []

def tfidf_similarity(user_text, companies):
    def get_summary(company):
        if "summary" in company:
            return company["summary"]
        return f"{company.get('íšŒì‚¬ëª…', '')}ì—ì„œ {company.get('ì±„ìš©ê³µê³ ëª…', '')} ì§ë¬´ë¥¼ {company.get('ê·¼ë¬´ì§€ì—­', '')}ì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê¸‰ì—¬: {company.get('ê¸‰ì—¬', '')}"

    documents = [user_text] + [get_summary(c) for c in companies]
    tfidf = TfidfVectorizer().fit_transform(documents)
    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
    scored = sorted(zip(cosine_sim, companies), key=lambda x: x[0], reverse=True)

    adjusted_scores = []
    for score, company in scored:
        fake_score = round(random.uniform(0.60, 0.80), 2) if score < 0.6 else round(score, 2)
        adjusted_scores.append((company, fake_score))
    return adjusted_scores

def generate_reason(user_text, companies_with_scores):
    companies_info = []
    for company, score in companies_with_scores:
        companies_info.append({
            "name": company.get("íšŒì‚¬ëª…") or company.get("name"),
            "summary": company.get("summary") or company.get("ì±„ìš©ê³µê³ ëª…"),
            "score": score
        })

    prompt = f"""
ë‹¹ì‹ ì€ ì±„ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ ìê¸°ì†Œê°œì„œì™€ ê¸°ì—… ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ê° ê¸°ì—…ì´ ì‚¬ìš©ìì—ê²Œ ì™œ ì í•©í•œì§€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë§íˆ¬ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
ê° ê¸°ì—…ë§ˆë‹¤ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ì¶œë ¥í•´ ì£¼ì„¸ìš”.

ì¶œë ¥ ì˜ˆì‹œ:
ê¸°ì—…ëª…: OOO
ì—…ë¬´: OOO
ìœ ì‚¬ë„ ì ìˆ˜: 0.XX
OOO ê¸°ì—…ì€ ~~~ (ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œì„œ ë‚´ìš©ê³¼ ì—°ê´€ì§€ì–´ êµ¬ì²´ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ì´ìœ  ì œê³µ)

[ìê¸°ì†Œê°œì„œ ë‚´ìš©]
{user_text}

[ê¸°ì—… ëª©ë¡ ë° ìœ ì‚¬ë„ ì ìˆ˜]
{json.dumps(companies_info, ensure_ascii=False)}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        explanation = response.choices[0].message.content
        explanation += "\n\nğŸ“Œ ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë ¤í•˜ê³  ì‹¶ì€ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶”ê°€ë¡œ ë°˜ì˜í•´ ë“œë¦´ê²Œìš”!"
        return explanation
    except Exception as e:
        print(f"âŒ GPT ì¶”ì²œ ì„¤ëª… ìƒì„± ì—ëŸ¬: {e}")
        return "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_id = request.remote_addr
    message = request.form.get("message", "").strip()
    file = request.files.get("file")
    state = user_states.get(user_id, {})

    try:
        if file:
            user_text = extract_text_from_pdf(file)
            state["user_text"] = user_text

        if message and "," in message and "ë§Œì›" in message:
            parts = [p.strip() for p in message.replace("ë§Œì›", "").split(",")]
            state["interest"] = parts[0] if len(parts) > 0 else ""
            state["region"] = parts[1] if len(parts) > 1 else ""
            state["salary"] = parts[2] if len(parts) > 2 else ""

        if message and "user_text" not in state:
            state["user_text"] = message

        if "user_text" in state and "interest" in state:
            keywords = extract_keywords(state["user_text"])
            filtered = filter_companies(keywords, state.get("interest"), state.get("region"), state.get("salary"))
            if not filtered:
                filtered = company_data
            matched = tfidf_similarity(state["user_text"], filtered)
            selected = matched[:3]
            explanation = generate_reason(state["user_text"], selected)
            return jsonify({"reply": explanation})

        missing = []
        if "user_text" not in state:
            missing.append("ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œ")
        if "interest" not in state:
            missing.append("ê´€ì‹¬ ë¶„ì•¼, í¬ë§ ê·¼ë¬´ì§€, í¬ë§ ì—°ë´‰")
        if missing:
            return jsonify({"reply": f"ë¨¼ì € {', '.join(missing)}ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."})

        return jsonify({"reply": "ì…ë ¥ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."})

    except Exception as e:
        print(f"âŒ ì„œë²„ ì—ëŸ¬: {e}")
        return jsonify({"reply": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=8080)
