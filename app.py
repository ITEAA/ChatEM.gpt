from flask import Flask, request, jsonify, render_template
import pandas as pd
import json
import openai
import os
import fitz  # PyMuPDF
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)

# âœ… OpenAI API í‚¤ ì„¤ì •
openai.api_key = "your-openai-api-key"  # ì‹¤ì œ í‚¤ë¡œ êµì²´

# âœ… ChatEM ê¸°ì—… ë°ì´í„° ë¡œë“œ
with open("ChatEM_top20_companies.json", encoding="utf-8") as f:
    top20_data = json.load(f)
df_companies = pd.DataFrame(top20_data)

# âœ… PDF ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
def read_file_content(file):
    filename = file.filename.lower()
    if filename.endswith(".pdf"):
        with fitz.open(stream=file.read(), filetype="pdf") as doc:
            return "\n".join([page.get_text() for page in doc])
    elif filename.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return ""

# âœ… GPT í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords_gpt(text):
    prompt = f"ë‹¤ìŒ ìê¸°ì†Œê°œì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 5ê°œë¥¼ ë½‘ì•„ì¤˜:\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )
    return response['choices'][0]['message']['content'].strip().split('\n')

# âœ… ê¸°ì—… ì¶”ì²œ
def recommend_companies(user_keywords):
    user_profile = " ".join(user_keywords)
    df_companies["combined_text"] = (
        df_companies["name"].fillna('') + " " +
        df_companies["summary"].fillna('') + " " +
        df_companies["region"].fillna('') + " " +
        df_companies["industry"].fillna('')
    )
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(df_companies["combined_text"].tolist() + [user_profile])
    cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])[0]
    df_companies["ìœ ì‚¬ë„"] = cosine_sim
    top = df_companies.sort_values(by="ìœ ì‚¬ë„", ascending=False).head(3)
    return top

# âœ… index í˜ì´ì§€
@app.route("/")
def index():
    return render_template("index.html")

# âœ… íŒŒì¼ ë˜ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ ë¼ìš°íŠ¸
@app.route("/chat", methods=["POST"])
def chat():
    file = request.files.get("file")
    text = request.form.get("message", "").strip()
    interest = request.form.get("interest", "").strip()
    region = request.form.get("region", "").strip()
    salary = request.form.get("salary", "").strip()

    # ğŸ” íŒŒì¼ì´ ìˆìœ¼ë©´ íŒŒì¼ ë‚´ìš© ì‚¬ìš©
    if file:
        try:
            text = read_file_content(file)
        except Exception as e:
            return jsonify({"reply": f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 400

    if not text:
        return jsonify({"reply": "ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."}), 400

    # ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ
    try:
        keywords = extract_keywords_gpt(text)
        if interest: keywords.append(interest)
        if region: keywords.append(region)
        if salary: keywords.append(salary)
    except Exception as e:
        return jsonify({"reply": f"GPT í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"}), 500

    # ğŸ” ê¸°ì—… ì¶”ì²œ
    try:
        results = recommend_companies(keywords)
        descriptions = []
        for _, row in results.iterrows():
            desc = f"{row['name']}ì—ì„œ {row['summary']} ì§ë¬´ë¥¼ ì±„ìš© ì¤‘ì´ë©°, ìœ„ì¹˜ëŠ” {row['region']}ì…ë‹ˆë‹¤."
            descriptions.append(desc)
        reply = "\n\n".join(descriptions)
        return jsonify({"reply": reply})
    except Exception as e:
        return jsonify({"reply": f"ê¸°ì—… ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(debug=True)
