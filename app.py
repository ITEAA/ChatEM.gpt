import os
import json
import fitz  # PyMuPDF
import openai
import random
import xml.etree.ElementTree as ET
import requests
import pandas as pd

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from werkzeug.utils import secure_filename
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
CORS(app)

openai.api_key = os.getenv("OPENAI_API_KEY") or "your-api-key"
GG_API_KEY = "8af0f404ca144249be0cfab9728b619b"
GG_API_URL = "https://openapi.gg.go.kr/EmplmntInfoStus"

user_states = {}

with open("ChatEM_top20_companies.json", "r", encoding="utf-8") as f:
    company_data = json.load(f)

def extract_text_from_pdf(pdf_file):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    text = "\n".join(page.get_text() for page in doc)
    return text.strip()

def extract_keywords(text):
    prompt = f"""
    ë‹¤ìŒ ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.
    - 5~10ê°œ ì •ë„ ë½‘ì•„ì¤˜.
    - í‚¤ì›Œë“œëŠ” ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•´ì¤˜.

    ë‚´ìš©:
    {text}
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        result = response.choices[0].message.content
        return [kw.strip() for kw in result.split(",") if kw.strip()]
    except Exception as e:
        print(f"âŒ GPT í˜¸ì¶œ ì—ëŸ¬: {e}")
        return []

def filter_companies(keywords, interest, region, salary):
    def score(company):
        base_score = 0
        if any(kw in (company.get("summary") or "") for kw in keywords):
            base_score += 1
        if interest and interest in (company.get("summary") or ""):
            base_score += 0.3
        if region and region in (company.get("region") or ""):
            base_score += 0.3
        if salary and str(salary) in (company.get("salary") or ""):
            base_score += 0.2
        return base_score

    return sorted(company_data, key=score, reverse=True)

def tfidf_similarity(user_text, companies):
    def get_summary(company):
        return company.get("summary") or f"{company.get('íšŒì‚¬ëª…', '')} - {company.get('ì±„ìš©ê³µê³ ëª…', '')}"

    documents = [user_text] + [get_summary(c) for c in companies]
    tfidf = TfidfVectorizer().fit_transform(documents)
    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:]).flatten()
    return sorted(zip(companies, cosine_sim), key=lambda x: x[1], reverse=True)

def generate_reason(user_text, companies_with_scores):
    companies_info = []
    for company, score in companies_with_scores:
        companies_info.append({
            "name": company.get("íšŒì‚¬ëª…") or company.get("name"),
            "summary": company.get("summary") or company.get("ì±„ìš©ê³µê³ ëª…"),
            "score": round(score, 2),
            "url": company.get("url") or company.get("ì±„ìš©ì •ë³´URL")
        })

    prompt = f"""
ë‹¹ì‹ ì€ ì±„ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ê° ê¸°ì—…ì´ ì‚¬ìš©ìì˜ ê²½ë ¥ê³¼ ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

ê¸°ì—…ëª…: OOO
ì—…ë¬´: OOO
ìœ ì‚¬ë„ ì ìˆ˜: 0.XX
ì„¤ëª…: (ë¶„ì„ê°€ì˜ ì‹œì„ ì—ì„œ ìê¸°ì†Œê°œì„œì˜ íŠ¹ì • ê²½í—˜ê³¼ ì§ë¬´ ì—°ê²°)

[ìê¸°ì†Œê°œì„œ ë‚´ìš©]
{user_text}

[ê¸°ì—… ëª©ë¡ ë° ìœ ì‚¬ë„ ì ìˆ˜]
{json.dumps(companies_info, ensure_ascii=False)}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        explanation = response.choices[0].message.content
        explanation += "\n\nğŸ“Œ ë” ê¶ê¸ˆí•œ ì ì´ë‚˜ ê³ ë ¤í•˜ê³  ì‹¶ì€ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ì¶”ê°€ë¡œ ë°˜ì˜í•´ ë“œë¦´ê²Œìš”!"
        return explanation
    except Exception as e:
        print(f"âŒ GPT ì¶”ì²œ ì„¤ëª… ìƒì„± ì—ëŸ¬: {e}")
        return "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@app.route("/")
def index():
    return render_template("index.html")

@app.route("/chat", methods=["POST"])
def chat():
    user_id = request.remote_addr
    message = request.form.get("message", "").strip()
    file = request.files.get("file")
    state = user_states.get(user_id, {})

    try:
        if file:
            user_text = extract_text_from_pdf(file)
            state["user_text"] = user_text

        if message and "," in message and "ë§Œì›" in message:
            parts = [p.strip().replace("ë§Œì›", "") for p in message.split(",")]
            state["interest"] = parts[0] if len(parts) > 0 else ""
            state["region"] = parts[1] if len(parts) > 1 else ""
            state["salary"] = parts[2] if len(parts) > 2 else ""

        if message and "user_text" not in state:
            state["user_text"] = message

        if "user_text" in state:
            keywords = extract_keywords(state["user_text"])
            filtered = filter_companies(keywords, state.get("interest"), state.get("region"), state.get("salary"))
            matched = tfidf_similarity(state["user_text"], filtered)
            selected = matched[:3] if "ë” ì¶”ì²œí•´ì¤˜" not in message else [matched[3]]
            explanation = generate_reason(state["user_text"], selected)
            return jsonify({"reply": explanation})

        missing = []
        if "user_text" not in state:
            missing.append("ìê¸°ì†Œê°œì„œ ë˜ëŠ” ì´ë ¥ì„œ")
        if missing:
            return jsonify({"reply": f"ë¨¼ì € {', '.join(missing)}ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."})

        return jsonify({"reply": "ì…ë ¥ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."})

    except Exception as e:
        print(f"âŒ ì„œë²„ ì—ëŸ¬: {e}")
        return jsonify({"reply": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=8080)
